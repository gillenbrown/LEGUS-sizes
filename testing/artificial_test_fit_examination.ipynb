{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from astropy import table, nddata\n",
    "from astropy.io import fits\n",
    "from scipy import signal, optimize\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec, colors\n",
    "import cmocean\n",
    "import betterplotlib as bpl\n",
    "\n",
    "bpl.set_style()\n",
    "\n",
    "# need to add the correct path to import utils\n",
    "legus_home_dir = Path(\".\").resolve().parent\n",
    "sys.path.append(str(legus_home_dir / \"pipeline\"))\n",
    "import utils\n",
    "import fit_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_factor = 2\n",
    "psf_size = 15\n",
    "snapshot_size = 30\n",
    "snapshot_size_oversampled = snapshot_size * oversampling_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we can load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = legus_home_dir / \"data\" / \"artificial\"\n",
    "image_data, _, _ = utils.get_drc_image(data_dir)\n",
    "\n",
    "error_data = fits.open(data_dir / \"size\" / \"sigma_electrons.fits\")[\"PRIMARY\"].data\n",
    "mask_data = fits.open(data_dir / \"size\" / \"mask_image.fits\")[\"PRIMARY\"].data\n",
    "\n",
    "psf_name = f\"psf_my_stars_{psf_size}_pixels_{oversampling_factor}x_oversampled.fits\"\n",
    "psf = fits.open(data_dir / \"size\" / psf_name)[\"PRIMARY\"].data\n",
    "psf_cen = int((psf.shape[1] - 1.0) / 2.0)\n",
    "# the convolution requires the psf to be normalized, and without any negative values\n",
    "psf = np.maximum(psf, 0)\n",
    "psf /= np.sum(psf)\n",
    "\n",
    "cat_name = (\n",
    "    f\"final_catalog_final_{snapshot_size}_pixels_psf_\"\n",
    "    f\"my_stars_{psf_size}_pixels_{oversampling_factor}x_oversampled.txt\"\n",
    ")\n",
    "cat_path = data_dir / \"size\" / cat_name\n",
    "cat = table.Table.read(str(cat_path), format=\"ascii.ecsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radial_profile(model_psf_bin_image, cluster_snapshot, mask, x_c, y_c):\n",
    "    \"\"\"\n",
    "    Make a radial profile of cluster and model pixel values\n",
    "\n",
    "    :param model_psf_bin_image: the model image on the same pixel scale as the data\n",
    "    :param cluster_snapshot: the data snapshot\n",
    "    :param mask: the mask indicating which pixel values to not use\n",
    "    :param x_c: X coordinate of the center in snapshot coordinates\n",
    "    :param y_c: Y coordinate of the center in snapshot coordinates\n",
    "    :return: Three numpy arrays: The radii of all pixel values, in sorted order, the\n",
    "             model values at these radii, then the data values at these radii\n",
    "    \"\"\"\n",
    "    # When fitting I treated the center of the pixels as the integer location, so do\n",
    "    # that here too\n",
    "    radii, model_ys, data_ys = [], [], []\n",
    "    for x in range(model_psf_bin_image.shape[1]):\n",
    "        for y in range(model_psf_bin_image.shape[0]):\n",
    "            if mask[y][x] > 0:\n",
    "                radii.append(fit_utils.distance(x, y, x_c, y_c))\n",
    "                model_ys.append(model_psf_bin_image[y, x])\n",
    "                data_ys.append(cluster_snapshot[y, x])\n",
    "\n",
    "    # sort everything in order of radii\n",
    "    idxs = np.argsort(radii)\n",
    "    return np.array(radii)[idxs], np.array(model_ys)[idxs], np.array(data_ys)[idxs]\n",
    "\n",
    "def bin_profile(radii, pixel_values, bin_size):\n",
    "    \"\"\"\n",
    "    Take an existing profile and bin it azimuthally\n",
    "\n",
    "    :param radii: Radii values corresponding to the pixel values\n",
    "    :param pixel_values: Values at the radii passed in\n",
    "    :param bin_size: How big the bins should be, in pixels\n",
    "    :return: Binned radii and pixel values\n",
    "    \"\"\"\n",
    "    binned_radii, binned_ys = [], []\n",
    "    for r_min in np.arange(0, int(np.ceil(max(radii))), bin_size):\n",
    "        r_max = r_min + bin_size\n",
    "        idx_above = np.where(r_min < radii)\n",
    "        idx_below = np.where(r_max > radii)\n",
    "        idx_good = np.intersect1d(idx_above, idx_below)\n",
    "\n",
    "        if len(idx_good) > 0:\n",
    "            binned_radii.append(r_min + 0.5 * bin_size)\n",
    "            binned_ys.append(np.mean(pixel_values[idx_good]))\n",
    "\n",
    "    return np.array(binned_radii), np.array(binned_ys)\n",
    "\n",
    "\n",
    "def rms(sigmas, x_c, y_c, max_radius):\n",
    "    \"\"\"\n",
    "    Calculate the RMS of the pixels within some radius\n",
    "\n",
    "    :param sigmas: Deviations of the pixels from the fit\n",
    "    :param x_c: X coordinate of the center, in coordinates of the sigmas snapshot\n",
    "    :param y_c: Y coordinate of the center, in coordinates of the sigmas snapshot\n",
    "    :param max_radius: Maximum radius to include in the calculation\n",
    "    :return: sqrt(mean(sigmas**2)) where r < max_radius\n",
    "    \"\"\"\n",
    "    good_sigmas = []\n",
    "    for x in range(sigmas.shape[1]):\n",
    "        for y in range(sigmas.shape[0]):\n",
    "            if fit_utils.distance(x, y, x_c, y_c) < max_radius:\n",
    "                good_sigmas.append(sigmas[y, x])\n",
    "\n",
    "    return np.sqrt(np.mean(np.array(good_sigmas) ** 2))\n",
    "\n",
    "\n",
    "def mad_of_cumulative(radii, model_cumulative, data_cumulative, max_radius):\n",
    "    \"\"\"\n",
    "    Calculate the median relative absolute deviation of the cumulative distribution\n",
    "    within some radius. This is median(abs(model - data) / data) where r < r_max\n",
    "\n",
    "    :param radii: List of radii\n",
    "    :param model_cumulative: Cumulative pixel values for the model as a function of r\n",
    "    :param data_cumulative: Cumulative pixel values for the data as a function of r\n",
    "    :param max_radius: Maximum radius to include in the calculation\n",
    "    :return: median(abs(model - data) / data) where r < r_max\n",
    "    \"\"\"\n",
    "    mask_good = radii < max_radius\n",
    "    diffs = np.abs(model_cumulative - data_cumulative) / data_cumulative\n",
    "    return np.median(diffs[mask_good])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_set(\n",
    "    cluster_snapshot,\n",
    "    uncertainty_snapshot,\n",
    "    mask,\n",
    "    true_params,\n",
    "    fit_params,\n",
    "    true_r_eff,\n",
    "    fit_r_eff,\n",
    "#     estimated_bg,\n",
    "#     bg_scatter,\n",
    "    radial_weighting,\n",
    "    save_loc\n",
    "):\n",
    "    params1 = true_params\n",
    "    params2 = fit_params\n",
    "    \n",
    "    # create copies of the image\n",
    "    cluster_snapshot = cluster_snapshot.copy()\n",
    "    uncertainty_snapshot = uncertainty_snapshot.copy()\n",
    "    # do the radial weighting. Need to get the data coordinates of the center\n",
    "    weight_snapshot = fit_utils.radial_weighting(\n",
    "        uncertainty_snapshot,\n",
    "        fit_utils.oversampled_to_image(params1[1], oversampling_factor),\n",
    "        fit_utils.oversampled_to_image(params1[2], oversampling_factor),\n",
    "        style=radial_weighting,\n",
    "    )\n",
    "    \n",
    "    mask = mask.copy()\n",
    "    \n",
    "    # when making the true image, I do not know the true luminosity. But I do know the \n",
    "    # peak value, so I can choose an arbitrary value then scale. But I have to do this \n",
    "    # without the background (because it's the peak of the cluster itself), \n",
    "    # then add it back.\n",
    "    true_peak = params1[0]  # save the value\n",
    "    true_bg = params1[-1]\n",
    "    params1[0] = 4  # arbitrary value\n",
    "    params1[-1] = 0  # will add back later\n",
    "    model_image1, model_psf_image1, model_psf_bin_image1 = fit_utils.create_model_image(\n",
    "        *params1, psf, snapshot_size_oversampled, oversampling_factor\n",
    "    )\n",
    "    scale_factor = true_peak / np.max(model_psf_bin_image1)\n",
    "    model_image1 *= scale_factor\n",
    "    model_psf_image1 *= scale_factor\n",
    "    model_psf_bin_image1 *= scale_factor\n",
    "    # then add the background to each\n",
    "    model_image1 += true_bg\n",
    "    model_psf_image1 += true_bg\n",
    "    model_psf_bin_image1 += true_bg\n",
    "    # and reset the parameter value for later use\n",
    "    params1[-1] = true_bg\n",
    "    \n",
    "    # the fit image needs no such changes\n",
    "    model_image2, model_psf_image2, model_psf_bin_image2 = fit_utils.create_model_image(\n",
    "        *params2, psf, snapshot_size_oversampled, oversampling_factor\n",
    "    )\n",
    "\n",
    "    diff_image1 = cluster_snapshot - model_psf_bin_image1\n",
    "    diff_image2 = cluster_snapshot - model_psf_bin_image2\n",
    "    sigma_image1 = weight_snapshot * diff_image1 / uncertainty_snapshot\n",
    "    sigma_image2 = weight_snapshot * diff_image2 / uncertainty_snapshot\n",
    "    \n",
    "    # have zeros in the sigma image where the mask has zeros, but leave it unmodified\n",
    "    # otherwise\n",
    "    sigma_image1 *= np.minimum(mask, 1.0)\n",
    "    sigma_image2 *= np.minimum(mask, 1.0)\n",
    "\n",
    "    # set up the normalizations and colormaps\n",
    "    # Use the data image to get the normalization that will be used in all plots. Base\n",
    "    # it on the data so that it is the same in all bootstrap iterations\n",
    "    vmax = 2 * np.max(cluster_snapshot)\n",
    "    linthresh = 3 * np.min(uncertainty_snapshot)\n",
    "    data_norm = colors.SymLogNorm(\n",
    "        vmin=-vmax, vmax=vmax, linthresh=linthresh, base=10\n",
    "    )\n",
    "    sigma_norm = colors.Normalize(vmin=-10, vmax=10)\n",
    "    u_norm = colors.Normalize(0, vmax=1.2 * np.max(uncertainty_snapshot))\n",
    "    m_norm = colors.Normalize(0, vmax=np.max(mask))\n",
    "    w_norm = colors.LogNorm(0.1, np.max(weight_snapshot))\n",
    "\n",
    "    data_cmap = bpl.cm.lisbon\n",
    "    sigma_cmap = cmocean.cm.tarn  # \"bwr_r\" also works\n",
    "    u_cmap = cmocean.cm.deep_r\n",
    "    m_cmap = cmocean.cm.gray_r\n",
    "    w_cmap = cmocean.cm.dense_r\n",
    "\n",
    "    # create the figure and add all the subplots\n",
    "    fig = plt.figure(figsize=[25, 15])\n",
    "    gs = gridspec.GridSpec(\n",
    "        nrows=6,\n",
    "        ncols=5,\n",
    "        width_ratios=[10, 10, 10, 1, 15],  # have a dummy spacer column\n",
    "        wspace=0.1,\n",
    "        hspace=0.7,\n",
    "        left=0.01,\n",
    "        right=0.98,\n",
    "        bottom=0.06,\n",
    "        top=0.94,\n",
    "    )\n",
    "    ax_d = fig.add_subplot(gs[2:4, 0], projection=\"bpl\")  # data\n",
    "    ax_u = fig.add_subplot(gs[4:, 0], projection=\"bpl\")  # uncertainty\n",
    "    ax_w = fig.add_subplot(gs[0:2:, 0], projection=\"bpl\")  # weights\n",
    "    \n",
    "    ax_r1 = fig.add_subplot(gs[0:2, 1], projection=\"bpl\")  # raw model\n",
    "    ax_f1 = fig.add_subplot(gs[2:4, 1], projection=\"bpl\")  # full model (f for fit)\n",
    "    ax_s1 = fig.add_subplot(gs[4:, 1], projection=\"bpl\")  # sigma difference\n",
    "    \n",
    "    ax_r2 = fig.add_subplot(gs[0:2, 2], projection=\"bpl\")  # raw model\n",
    "    ax_f2 = fig.add_subplot(gs[2:4, 2], projection=\"bpl\")  # full model (f for fit)\n",
    "    ax_s2 = fig.add_subplot(gs[4:, 2], projection=\"bpl\")  # sigma difference\n",
    "    \n",
    "    \n",
    "    ax_pd = fig.add_subplot(\n",
    "        gs[0:3, 4], projection=\"bpl\"\n",
    "    )  # radial profile differential\n",
    "    ax_pc = fig.add_subplot(\n",
    "        gs[3:, 4], projection=\"bpl\"\n",
    "    )  # radial profile cumulative\n",
    "\n",
    "    # show the images in their respective panels\n",
    "    common_data = {\"norm\": data_norm, \"cmap\": data_cmap}\n",
    "    d_im = ax_d.imshow(cluster_snapshot, **common_data, origin=\"lower\")\n",
    "    u_im = ax_u.imshow(uncertainty_snapshot, norm=u_norm, cmap=u_cmap, origin=\"lower\")\n",
    "    w_im = ax_w.imshow(weight_snapshot, norm=w_norm, cmap=w_cmap, origin=\"lower\")\n",
    "    \n",
    "    r_im1 = ax_r1.imshow(model_image1, **common_data, origin=\"lower\")\n",
    "    f_im1 = ax_f1.imshow(model_psf_bin_image1, **common_data, origin=\"lower\")\n",
    "    s_im1 = ax_s1.imshow(sigma_image1, norm=sigma_norm, cmap=sigma_cmap, origin=\"lower\")\n",
    "    r_im2 = ax_r2.imshow(model_image2, **common_data, origin=\"lower\")\n",
    "    f_im2 = ax_f2.imshow(model_psf_bin_image2, **common_data, origin=\"lower\")\n",
    "    s_im2 = ax_s2.imshow(sigma_image2, norm=sigma_norm, cmap=sigma_cmap, origin=\"lower\")\n",
    "\n",
    "    fig.colorbar(d_im, ax=ax_d)\n",
    "    fig.colorbar(u_im, ax=ax_u)\n",
    "    fig.colorbar(w_im, ax=ax_w)\n",
    "    fig.colorbar(r_im1, ax=ax_r1)\n",
    "    fig.colorbar(f_im1, ax=ax_f1)\n",
    "    fig.colorbar(s_im1, ax=ax_s1)\n",
    "    fig.colorbar(r_im2, ax=ax_r2)\n",
    "    fig.colorbar(f_im2, ax=ax_f2)\n",
    "    fig.colorbar(s_im2, ax=ax_s2)\n",
    "\n",
    "    ax_d.set_title(\"Data\")\n",
    "    ax_u.set_title(\"Uncertainty\")\n",
    "    ax_w.set_title(\"Weight\")\n",
    "    \n",
    "    ax_r1.set_title(\"True\\nRaw Cluster Model\")\n",
    "    ax_f1.set_title(\"Model Convolved\\nwith PSF and Binned\")\n",
    "    ax_s1.set_title(\"(Data - Model)/Uncertainty\")\n",
    "    \n",
    "    ax_r2.set_title(\"Fit\\nRaw Cluster Model\")\n",
    "    ax_f2.set_title(\"Model Convolved\\nwith PSF and Binned\")\n",
    "    ax_s2.set_title(\"(Data - Model)/Uncertainty\")\n",
    "\n",
    "    for ax in [ax_d, ax_u, ax_w, ax_r1, ax_r2, ax_f1, ax_f1, ax_s1, ax_s2]:\n",
    "        ax.remove_labels(\"both\")\n",
    "        ax.remove_spines([\"all\"])\n",
    "\n",
    "#     # add an X marker to the location of the center\n",
    "#     # the rest are image coords\n",
    "#     x_image = fit_utils.oversampled_to_image(params1[1], oversampling_factor)\n",
    "#     y_image = fit_utils.oversampled_to_image(params1[2], oversampling_factor)\n",
    "#     for ax in [ax_d, ax_u, ax_s1, ax_s2]:\n",
    "#         ax.scatter([x_image], [y_image], marker=\"x\", c=bpl.almost_black)\n",
    "#     # make the marker white in the mask plot\n",
    "#     ax_m.scatter([x_image], [y_image], marker=\"x\", c=\"w\")\n",
    "\n",
    "    # Then make the radial plots. first background subtract\n",
    "    cluster_snapshot -= params1[7]\n",
    "    model_psf_bin_image1 -= params1[7]\n",
    "    model_psf_bin_image2 -= params2[7]\n",
    "\n",
    "    c_d = bpl.color_cycle[0]\n",
    "    c_m1 = bpl.color_cycle[1]\n",
    "    c_m2 = bpl.color_cycle[2]\n",
    "    # the center is in oversampled coords, fix that\n",
    "    x_c = fit_utils.oversampled_to_image(params1[1], oversampling_factor)\n",
    "    y_c = fit_utils.oversampled_to_image(params1[2], oversampling_factor)\n",
    "\n",
    "    radii, model_ys1, data_ys = create_radial_profile(\n",
    "        model_psf_bin_image1, cluster_snapshot, mask, x_c, y_c\n",
    "    )\n",
    "    radii, model_ys2, data_ys = create_radial_profile(\n",
    "        model_psf_bin_image2, cluster_snapshot, mask, x_c, y_c\n",
    "    )\n",
    "\n",
    "    ax_pd.scatter(radii, data_ys, c=c_d, s=5, alpha=1.0, label=\"Data\")\n",
    "    ax_pd.scatter(radii, model_ys1, c=c_m1, s=5, alpha=1.0, label=\"Best Fit\")\n",
    "    ax_pd.scatter(radii, model_ys2, c=c_m2, s=5, alpha=1.0, label=\"Guess\")\n",
    "    ax_pd.axhline(0, ls=\":\", c=bpl.almost_black) \n",
    "\n",
    "    # then bin this data to make the binned plot\n",
    "    ax_pd.plot(*bin_profile(radii, data_ys, 1.0), c=c_d, lw=5, label=\"Binned Data\")\n",
    "    ax_pd.plot(\n",
    "        *bin_profile(radii, model_ys1, 1.0), c=c_m1, lw=5, label=\"Binned True\"\n",
    "    )\n",
    "    ax_pd.plot(\n",
    "        *bin_profile(radii, model_ys2, 1.0), c=c_m2, lw=5, label=\"Binned Fit\"\n",
    "    )\n",
    "\n",
    "    ax_pd.legend(loc=\"upper right\")\n",
    "    ax_pd.add_labels(\n",
    "        \"Radius (pixels)\", \"Pixel Value [$e^{-}$]\"\n",
    "    )\n",
    "    # set min and max values so it's easier to flip through bootstrapping plots\n",
    "    y_min = np.min(cluster_snapshot)\n",
    "    y_max = np.max(cluster_snapshot)\n",
    "    # give them a bit of padding\n",
    "    diff = y_max - y_min\n",
    "    y_min -= 0.1 * diff\n",
    "    y_max += 0.1 * diff\n",
    "    ax_pd.set_limits(0, np.ceil(max(radii)), y_min, y_max)\n",
    "\n",
    "    # then make the cumulative one. The radii are already in order so this is easy\n",
    "    model_ys_cumulative1 = np.cumsum(model_ys1)\n",
    "    model_ys_cumulative2 = np.cumsum(model_ys2)\n",
    "    data_ys_cumulative = np.cumsum(data_ys)\n",
    "\n",
    "    ax_pc.plot(radii, data_ys_cumulative, c=c_d, label=\"Data\")\n",
    "    ax_pc.plot(radii, model_ys_cumulative1, c=c_m1, label=\"True\")\n",
    "    ax_pc.plot(radii, model_ys_cumulative2, c=c_m2, label=\"Fit\")\n",
    "    ax_pc.set_limits(0, np.ceil(max(radii)), 0, 1.2 * np.max(data_ys_cumulative))\n",
    "    ax_pc.legend(loc=\"upper left\")\n",
    "    ax_pc.add_labels(\n",
    "        \"Radius (pixels)\", \"Cumulative Pixel Values [$e^{-}$]\"\n",
    "    )\n",
    "\n",
    "    # the last one just has the list of parameters\n",
    "    ax_pc.easy_add_text(\n",
    "        \"Param = True - Fit\\n\"\n",
    "        f\"scale radius [pixels] = {params1[3]:.2g} - {params2[3]:.2g}\\n\"\n",
    "        f\"q (axis ratio) = {params1[4]:.2f} - {params2[4]:.2f}\\n\"\n",
    "        f\"position angle = {params1[5]:.2f} - {params2[5]:.2f}\\n\"\n",
    "        f\"$\\eta$ (power law slope) = {params1[6]:.2f} - {params2[6]:.2f}\\n\"\n",
    "        f\"background = {params1[7]:.2f} - {params2[7]:.2f}\\n\\n\"\n",
    "        \"$R_{eff}$ [pixels]\" + f\" = {true_r_eff:.2f} - {fit_r_eff:.2f}\\n\\n\"\n",
    "        f\"$\\chi^2$ = {np.sum(np.abs(sigma_image1)):,.4f} - {np.sum(np.abs(sigma_image2)):,.4f}\\n\\n\",\n",
    "#         f\"estimated background = {estimated_bg:.2f}$\\pm${bg_scatter:.2f}\\n\",\n",
    "        \"lower right\",\n",
    "        fontsize=15,\n",
    "    )\n",
    "    fig.savefig(save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then plot the guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a101b37a4b3b>:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=[25, 15])\n"
     ]
    }
   ],
   "source": [
    "# then find the correct row\n",
    "for row in cat:\n",
    "    # create the snapshot. We use ceiling to get the integer pixel values as python\n",
    "    # indexing does not include the final value. So when we calcualte the offset, it\n",
    "    # naturally gets biased low. Moving the center up fixes that in the easiest way.\n",
    "    x_cen = int(np.ceil(row[\"x_fitted_best\"]))\n",
    "    y_cen = int(np.ceil(row[\"y_fitted_best\"]))\n",
    "\n",
    "    # Get the snapshot, based on the size desired.\n",
    "    # Since we took the ceil of the center, go more in the negative direction (i.e.\n",
    "    # use ceil to get the minimum values). This only matters if the snapshot size is odd\n",
    "    x_min = x_cen - int(np.ceil(snapshot_size / 2.0))\n",
    "    x_max = x_cen + int(np.floor(snapshot_size / 2.0))\n",
    "    y_min = y_cen - int(np.ceil(snapshot_size / 2.0))\n",
    "    y_max = y_cen + int(np.floor(snapshot_size / 2.0))\n",
    "\n",
    "    data_snapshot = image_data[y_min:y_max, x_min:x_max].copy()\n",
    "    error_snapshot = error_data[y_min:y_max, x_min:x_max].copy()\n",
    "    mask_snapshot = mask_data[y_min:y_max, x_min:x_max].copy()\n",
    "\n",
    "    snapshot_x_cen_fit = row[\"x_fitted_best\"] - x_min\n",
    "    snapshot_y_cen_fit = row[\"y_fitted_best\"] - y_min\n",
    "    snapshot_x_cen_true = row[\"x\"] - x_min\n",
    "    snapshot_y_cen_true = row[\"y\"] - y_min\n",
    "    # Use the same mask region as was used in the actual fitting procedure\n",
    "    mask_snapshot = fit_utils.handle_mask(mask_snapshot, row[\"ID\"])\n",
    "    \n",
    "    best_fit_params = [\n",
    "        row[\"log_luminosity_best\"],\n",
    "        fit_utils.image_to_oversampled(snapshot_x_cen_fit, oversampling_factor),\n",
    "        fit_utils.image_to_oversampled(snapshot_y_cen_fit, oversampling_factor),\n",
    "        row[\"scale_radius_pixels_best\"],\n",
    "        row[\"axis_ratio_best\"],\n",
    "        row[\"position_angle_best\"],\n",
    "        row[\"power_law_slope_best\"],\n",
    "        row[\"local_background_best\"],\n",
    "    ]\n",
    "    true_params = [\n",
    "        row[\"peak_pixel_value_true\"],\n",
    "        fit_utils.image_to_oversampled(snapshot_x_cen_true, oversampling_factor),\n",
    "        fit_utils.image_to_oversampled(snapshot_y_cen_true, oversampling_factor),\n",
    "        row[\"scale_radius_pixels_true\"],\n",
    "        row[\"axis_ratio_true\"],\n",
    "        row[\"position_angle_true\"],\n",
    "        row[\"power_law_slope_true\"],\n",
    "        row[\"local_background_best\"],\n",
    "    ]\n",
    "    \n",
    "    plot_model_set(data_snapshot, error_snapshot, mask_snapshot,\n",
    "                   true_params, best_fit_params, \n",
    "                   row[\"reff_pixels_true\"], row['r_eff_pixels_rmax_15pix_best'],\n",
    "                   \"annulus\",\n",
    "                   f\"../data/artificial/size/cluster_fit_plots/fit_check_{row['ID']}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legus",
   "language": "python",
   "name": "legus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
